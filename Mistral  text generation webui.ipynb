{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNMEqcmIv0EmIgrAz+Mw2E3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B68WT_iWSEFX","executionInfo":{"status":"ok","timestamp":1696452098051,"user_tz":-330,"elapsed":1535571,"user":{"displayName":"Dealz Bunny","userId":"11151311946621479511"}},"outputId":"4a7b3625-59e6-47c4-dfaf-1db41db70229"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","Selecting previously unselected package libc-ares2:amd64.\n","(Reading database ... 120895 files and directories currently installed.)\n","Preparing to unpack .../libc-ares2_1.18.1-1ubuntu0.22.04.2_amd64.deb ...\n","Unpacking libc-ares2:amd64 (1.18.1-1ubuntu0.22.04.2) ...\n","Selecting previously unselected package libaria2-0:amd64.\n","Preparing to unpack .../libaria2-0_1.36.0-1_amd64.deb ...\n","Unpacking libaria2-0:amd64 (1.36.0-1) ...\n","Selecting previously unselected package aria2.\n","Preparing to unpack .../aria2_1.36.0-1_amd64.deb ...\n","Unpacking aria2 (1.36.0-1) ...\n","Setting up libc-ares2:amd64 (1.18.1-1ubuntu0.22.04.2) ...\n","Setting up libaria2-0:amd64 (1.36.0-1) ...\n","Setting up aria2 (1.36.0-1) ...\n","Processing triggers for man-db (2.10.2-1) ...\n","Processing triggers for libc-bin (2.35-0ubuntu3.1) ...\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n","\n","Cloning into 'text-generation-webui'...\n","remote: Enumerating objects: 11207, done.\u001b[K\n","remote: Total 11207 (delta 0), reused 0 (delta 0), pack-reused 11207\u001b[K\n","Receiving objects: 100% (11207/11207), 3.60 MiB | 27.94 MiB/s, done.\n","Resolving deltas: 100% (7661/7661), done.\n","/content/text-generation-webui\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m355.2/355.2 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.6/731.6 kB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m732.9/732.9 kB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.2/15.2 MB\u001b[0m \u001b[31m91.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.1/288.1 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.2/251.2 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.6/519.6 kB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.6/85.6 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m117.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m85.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m116.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m83.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m88.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m93.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.7/75.7 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.0/190.0 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.8/224.8 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.5/46.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.24.0 which is incompatible.\n","seaborn 0.12.2 requires numpy!=1.24.0,>=1.17, but you have numpy 1.24.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m\n","Download Results:\n","gid   |stat|avg speed  |path/URI\n","======+====+===========+=======================================================\n","d811fa|\u001b[1;32mOK\u001b[0m  |    60KiB/s|/content/text-generation-webui/models/Amethyst-13B-Mistral-GPTQ-localmodels/config.json\n","\n","Status Legend:\n","(OK):download completed.\n","\n","Download Results:\n","gid   |stat|avg speed  |path/URI\n","======+====+===========+=======================================================\n","8b4427|\u001b[1;32mOK\u001b[0m  |    18KiB/s|/content/text-generation-webui/models/Amethyst-13B-Mistral-GPTQ-localmodels/generation_config.json\n","\n","Status Legend:\n","(OK):download completed.\n","\n","Download Results:\n","gid   |stat|avg speed  |path/URI\n","======+====+===========+=======================================================\n","1a5bc3|\u001b[1;32mOK\u001b[0m  |   9.3KiB/s|/content/text-generation-webui/models/Amethyst-13B-Mistral-GPTQ-localmodels/special_tokens_map.json\n","\n","Status Legend:\n","(OK):download completed.\n","\n","Download Results:\n","gid   |stat|avg speed  |path/URI\n","======+====+===========+=======================================================\n","dec9c4|\u001b[1;32mOK\u001b[0m  |    12MiB/s|/content/text-generation-webui/models/Amethyst-13B-Mistral-GPTQ-localmodels/tokenizer.model\n","\n","Status Legend:\n","(OK):download completed.\n","\n","Download Results:\n","gid   |stat|avg speed  |path/URI\n","======+====+===========+=======================================================\n","c174c6|\u001b[1;32mOK\u001b[0m  |    94KiB/s|/content/text-generation-webui/models/Amethyst-13B-Mistral-GPTQ-localmodels/tokenizer_config.json\n","\n","Status Legend:\n","(OK):download completed.\n","\u001b[0m\n","Download Results:\n","gid   |stat|avg speed  |path/URI\n","======+====+===========+=======================================================\n","f5d176|\u001b[1;32mOK\u001b[0m  |   188MiB/s|/content/text-generation-webui/models/Amethyst-13B-Mistral-GPTQ-localmodels/gptq_model-4bit-128g.safetensors\n","\n","Status Legend:\n","(OK):download completed.\n","/content/text-generation-webui\n","2023-10-04 20:18:21 WARNING:\u001b[33mThe gradio \"share link\" feature uses a proprietary executable to create a reverse tunnel. Use it with care.\u001b[0m\n","2023-10-04 20:18:28.777506: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2023-10-04 20:18:33 INFO:\u001b[32mLoading settings from /content/settings.yaml...\u001b[0m\n","2023-10-04 20:18:33 INFO:\u001b[32mLoading /content/text-generation-webui/models/Amethyst-13B-Mistral-GPTQ-localmodels...\u001b[0m\n","2023-10-04 20:19:10 WARNING:\u001b[33mmodels/Amethyst-13B-Mistral-GPTQ-localmodels/tokenizer_config.json is different from the original LlamaTokenizer file. It is either customized or outdated.\u001b[0m\n","2023-10-04 20:19:10 WARNING:\u001b[33mmodels/Amethyst-13B-Mistral-GPTQ-localmodels/special_tokens_map.json is different from the original LlamaTokenizer file. It is either customized or outdated.\u001b[0m\n","2023-10-04 20:19:10 INFO:\u001b[32mLoaded the model in 37.81 seconds.\n","\u001b[0m\n","2023-10-04 20:19:10 INFO:\u001b[32mLoading the extension \"gallery\"...\u001b[0m\n","Running on local URL:  http://127.0.0.1:7860\n","Running on public URL: https://cfd367e3722979a9f6.gradio.live\n","\n","This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n","Output generated in 9.67 seconds (7.65 tokens/s, 74 tokens, context 21, seed 362136245)\n","Output generated in 2.06 seconds (10.68 tokens/s, 22 tokens, context 28, seed 1169332760)\n","Output generated in 11.21 seconds (17.75 tokens/s, 199 tokens, context 57, seed 1828901117)\n","Output generated in 11.81 seconds (16.85 tokens/s, 199 tokens, context 259, seed 202025655)\n","2023-10-04 20:25:24 INFO:\u001b[32mSaved /content/text-generation-webui/presets/My Preset.yaml.\u001b[0m\n","Output generated in 7.46 seconds (16.36 tokens/s, 122 tokens, context 26, seed 1753980985)\n","Output generated in 1.82 seconds (7.14 tokens/s, 13 tokens, context 144, seed 1581626712)\n","Output generated in 27.41 seconds (17.88 tokens/s, 490 tokens, context 10, seed 1159003058)\n","Output generated in 1.78 seconds (7.86 tokens/s, 14 tokens, context 72, seed 676135585)\n","Output generated in 9.48 seconds (17.94 tokens/s, 170 tokens, context 100, seed 559041131)\n","2023-10-04 20:31:58 INFO:\u001b[32mSaved /content/text-generation-webui/instruction-templates/My Template.yaml.\u001b[0m\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/gradio/routes.py\", line 427, in run_predict\n","    output = await app.get_blocks().process_api(\n","  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1323, in process_api\n","    result = await self.call_function(\n","  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1067, in call_function\n","    prediction = await utils.async_iteration(iterator)\n","  File \"/usr/local/lib/python3.10/dist-packages/gradio/utils.py\", line 336, in async_iteration\n","    return await iterator.__anext__()\n","  File \"/usr/local/lib/python3.10/dist-packages/gradio/utils.py\", line 329, in __anext__\n","    return await anyio.to_thread.run_sync(\n","  File \"/usr/local/lib/python3.10/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n","    return await get_asynclib().run_sync_in_worker_thread(\n","  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n","    return await future\n","  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n","    result = context.run(func, *args)\n","  File \"/usr/local/lib/python3.10/dist-packages/gradio/utils.py\", line 312, in run_sync_iterator_async\n","    return next(iterator)\n","  File \"/content/text-generation-webui/modules/chat.py\", line 308, in generate_chat_reply_wrapper\n","    for i, history in enumerate(generate_chat_reply(text, state, regenerate, _continue, loading_message=True)):\n","  File \"/content/text-generation-webui/modules/chat.py\", line 293, in generate_chat_reply\n","    for history in chatbot_wrapper(text, state, regenerate=regenerate, _continue=_continue, loading_message=loading_message):\n","  File \"/content/text-generation-webui/modules/chat.py\", line 232, in chatbot_wrapper\n","    prompt = generate_chat_prompt(text, state, **kwargs)\n","  File \"/content/text-generation-webui/modules/chat.py\", line 84, in generate_chat_prompt\n","    'instruct': get_turn_substrings(state, instruct=True)\n","  File \"/content/text-generation-webui/modules/chat.py\", line 62, in get_turn_substrings\n","    'bot_turn': '<|bot|>' + template.split('<|bot|>')[1],\n","IndexError: list index out of range\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/gradio/routes.py\", line 427, in run_predict\n","    output = await app.get_blocks().process_api(\n","  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1323, in process_api\n","    result = await self.call_function(\n","  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1067, in call_function\n","    prediction = await utils.async_iteration(iterator)\n","  File \"/usr/local/lib/python3.10/dist-packages/gradio/utils.py\", line 336, in async_iteration\n","    return await iterator.__anext__()\n","  File \"/usr/local/lib/python3.10/dist-packages/gradio/utils.py\", line 329, in __anext__\n","    return await anyio.to_thread.run_sync(\n","  File \"/usr/local/lib/python3.10/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n","    return await get_asynclib().run_sync_in_worker_thread(\n","  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n","    return await future\n","  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n","    result = context.run(func, *args)\n","  File \"/usr/local/lib/python3.10/dist-packages/gradio/utils.py\", line 312, in run_sync_iterator_async\n","    return next(iterator)\n","  File \"/content/text-generation-webui/modules/chat.py\", line 308, in generate_chat_reply_wrapper\n","    for i, history in enumerate(generate_chat_reply(text, state, regenerate, _continue, loading_message=True)):\n","  File \"/content/text-generation-webui/modules/chat.py\", line 293, in generate_chat_reply\n","    for history in chatbot_wrapper(text, state, regenerate=regenerate, _continue=_continue, loading_message=loading_message):\n","  File \"/content/text-generation-webui/modules/chat.py\", line 232, in chatbot_wrapper\n","    prompt = generate_chat_prompt(text, state, **kwargs)\n","  File \"/content/text-generation-webui/modules/chat.py\", line 84, in generate_chat_prompt\n","    'instruct': get_turn_substrings(state, instruct=True)\n","  File \"/content/text-generation-webui/modules/chat.py\", line 62, in get_turn_substrings\n","    'bot_turn': '<|bot|>' + template.split('<|bot|>')[1],\n","IndexError: list index out of range\n","Output generated in 2.80 seconds (9.99 tokens/s, 28 tokens, context 277, seed 1928790416)\n","Output generated in 14.89 seconds (16.25 tokens/s, 242 tokens, context 322, seed 270305995)\n","Output generated in 22.90 seconds (15.85 tokens/s, 363 tokens, context 577, seed 2132656005)\n","Traceback (most recent call last):\n","  File \"/content/text-generation-webui/server.py\", line 233, in <module>\n","    time.sleep(0.5)\n","KeyboardInterrupt\n","Killing tunnel 127.0.0.1:7860 <> https://cfd367e3722979a9f6.gradio.live\n","^C\n"]}],"source":["%cd /content\n","!apt-get -y install -qq aria2\n","\n","!git clone -b main https://github.com/camenduru/text-generation-webui\n","# !git clone -b v2.6 https://github.com/camenduru/text-generation-webui\n","\n","%cd /content/text-generation-webui\n","!pip install -q -r requirements.txt\n","\n","!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/TheBloke/Amethyst-13B-Mistral-GPTQ/resolve/main/config.json -d /content/text-generation-webui/models/Amethyst-13B-Mistral-GPTQ-localmodels -o config.json\n","!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/TheBloke/Amethyst-13B-Mistral-GPTQ/resolve/main/generation_config.json -d /content/text-generation-webui/models/Amethyst-13B-Mistral-GPTQ-localmodels -o generation_config.json\n","!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/TheBloke/Amethyst-13B-Mistral-GPTQ/resolve/main/special_tokens_map.json -d /content/text-generation-webui/models/Amethyst-13B-Mistral-GPTQ-localmodels -o special_tokens_map.json\n","!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/TheBloke/Amethyst-13B-Mistral-GPTQ/resolve/main/tokenizer.model -d /content/text-generation-webui/models/Amethyst-13B-Mistral-GPTQ-localmodels -o tokenizer.model\n","!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/TheBloke/Amethyst-13B-Mistral-GPTQ/resolve/main/tokenizer_config.json -d /content/text-generation-webui/models/Amethyst-13B-Mistral-GPTQ-localmodels -o tokenizer_config.json\n","!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/TheBloke/Amethyst-13B-Mistral-GPTQ/resolve/main/model.safetensors -d /content/text-generation-webui/models/Amethyst-13B-Mistral-GPTQ-localmodels -o gptq_model-4bit-128g.safetensors\n","\n","!echo \"dark_theme: true\" > /content/settings.yaml\n","!echo \"chat_style: wpp\" >> /content/settings.yaml\n","!echo \"mode: 'instruct'\" >> /content/settings.yaml\n","!echo \"instruction_template: 'Llama-v2'\" >> /content/settings.yaml\n","\n","%cd /content/text-generation-webui\n","!python server.py --share --settings /content/settings.yaml --loader ExLlama_HF --model /content/text-generation-webui/models/Amethyst-13B-Mistral-GPTQ-localmodels"]},{"cell_type":"code","source":["user: '[INST] '\n","bot: ' [/INST]'\n","turn_template: <s><|user|><|user-message|><|bot|>\\n<|bot-message|></s>\\n"],"metadata":{"id":"7cgUq0ToVT-W"},"execution_count":null,"outputs":[]}]}